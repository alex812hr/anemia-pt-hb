"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PREDICCIÃ“N DE ANEMIA CON MACHINE LEARNING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Dataset: TACNA_Final_Corregido.csv
Modelos: Logistic Regression, Random Forest, Gradient Boosting

TÃ‰CNICAS IMPLEMENTADAS:
- TÃ©cnicas de balanceo: SMOTE, Class Weight, Undersampling
- OptimizaciÃ³n: GridSearchCV
- EvaluaciÃ³n: F1-Score, Recall, Precision, AUC-ROC

Autor: Generado automÃ¡ticamente
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# IMPORTACIÃ“N DE LIBRERÃAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Scikit-learn: Modelos y mÃ©tricas
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, roc_auc_score, roc_curve
)

# Imbalanced-learn: TÃ©cnicas de balanceo
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.combine import SMOTETomek

import warnings
import os
warnings.filterwarnings('ignore')

# ConfiguraciÃ³n de visualizaciÃ³n
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['figure.figsize'] = (12, 6)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIÃ“N: CARGAR Y EXPLORAR DATOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def load_and_explore(filepath):
    """
    Carga el dataset y realiza exploraciÃ³n inicial.
    
    ParÃ¡metros:
        filepath: Ruta al archivo CSV
    
    Retorna:
        DataFrame con los datos cargados
    """
    print("=" * 70)
    print("ğŸ“Š CARGA Y EXPLORACIÃ“N DE DATOS")
    print("=" * 70)
    
    df = pd.read_csv(filepath)
    print(f"\nâœ… Dataset cargado: {df.shape[0]} filas x {df.shape[1]} columnas")
    
    # DistribuciÃ³n del target
    print(f"\nğŸ“Œ DistribuciÃ³n de Dx_anemia:")
    print(df['Dx_anemia'].value_counts(dropna=False))
    
    return df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIÃ“N: PREPROCESAMIENTO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def preprocess(df):
    """
    Preprocesa los datos para modelado:
    - Filtra registros vÃ¡lidos
    - Crea target binario
    - Imputa valores faltantes
    - Codifica variables categÃ³ricas
    
    Retorna:
        X_train, X_test, y_train, y_test, scaler, feature_names
    """
    print("\n" + "=" * 70)
    print("ğŸ”§ PREPROCESAMIENTO DE DATOS")
    print("=" * 70)
    
    # 1. Filtrar registros con diagnÃ³stico vÃ¡lido
    df_clean = df[df['Dx_anemia'].notna()].copy()
    
    # 2. Crear target binario (0: Normal, 1: Anemia)
    df_clean['anemia_binary'] = df_clean['Dx_anemia'].apply(
        lambda x: 0 if x == 'Normal' else 1
    )
    
    # 3. Seleccionar features
    feature_cols = ['Sexo', 'EdadMeses', 'Peso', 'Talla', 'PTZ', 'ZTE', 'ZPE', 
                    'AlturaREN', 'Suplementacion', 'SIS']
    available = [c for c in feature_cols if c in df_clean.columns]
    
    # 4. Preparar dataset
    df_model = df_clean[available + ['anemia_binary']].copy()
    df_model = df_model.dropna(subset=['EdadMeses', 'Peso', 'Talla'])
    
    # 5. Imputar valores faltantes
    for col in ['PTZ', 'ZTE', 'ZPE', 'AlturaREN']:
        if col in df_model.columns:
            df_model[col] = df_model[col].fillna(df_model[col].median())
    
    for col in ['Suplementacion', 'SIS']:
        if col in df_model.columns:
            df_model[col] = pd.to_numeric(df_model[col], errors='coerce').fillna(0)
    
    # 6. Codificar Sexo
    if 'Sexo' in df_model.columns:
        df_model['Sexo'] = df_model['Sexo'].map({'M': 1, 'F': 0}).fillna(0)
    
    print(f"\nâœ… Dataset procesado: {len(df_model)} registros")
    print(f"   Sin anemia: {(df_model['anemia_binary'] == 0).sum()}")
    print(f"   Con anemia: {(df_model['anemia_binary'] == 1).sum()}")
    
    # 7. DivisiÃ³n train/test
    X = df_model[available]
    y = df_model['anemia_binary']
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # 8. Escalar
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    print(f"\nğŸ“Š DivisiÃ³n: Train={len(X_train)} | Test={len(X_test)}")
    
    return X_train_scaled, X_test_scaled, y_train, y_test, scaler, available


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIÃ“N: EVALUAR MODELO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def evaluate(model, X_test, y_test, name, technique):
    """
    EvalÃºa un modelo y retorna mÃ©tricas en diccionario.
    
    MÃ©tricas calculadas:
    - Accuracy: ProporciÃ³n de predicciones correctas
    - Precision: TP / (TP + FP) - Evita falsos positivos
    - Recall: TP / (TP + FN) - Evita falsos negativos (importante en salud)
    - F1-Score: Media armÃ³nica de Precision y Recall
    - AUC-ROC: Ãrea bajo la curva ROC
    """
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:, 1]
    
    return {
        'Modelo': name,
        'TÃ©cnica': technique,
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred),
        'Recall': recall_score(y_test, y_pred),
        'F1-Score': f1_score(y_test, y_pred),
        'AUC-ROC': roc_auc_score(y_test, y_prob)
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIÃ“N: ENTRENAR CON TODAS LAS TÃ‰CNICAS DE BALANCEO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def train_all_techniques(X_train, X_test, y_train, y_test):
    """
    Entrena modelos con mÃºltiples tÃ©cnicas de balanceo:
    
    TÃ‰CNICAS DE BALANCEO:
    1. Sin Balanceo: Baseline
    2. SMOTE: Genera muestras sintÃ©ticas de la clase minoritaria
    3. Random Undersampling: Reduce la clase mayoritaria
    4. SMOTETomek: SMOTE + limpieza de muestras ruidosas
    5. Class Weight: Penaliza errores en clase minoritaria
    
    Retorna: DataFrame con todos los resultados
    """
    print("\n" + "=" * 70)
    print("ğŸš€ ENTRENAMIENTO CON TÃ‰CNICAS DE BALANCEO")
    print("=" * 70)
    
    all_results = []
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # TÃ‰CNICAS DE RESAMPLING
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    techniques = {
        'Sin Balanceo': None,
        'SMOTE': SMOTE(random_state=42),
        'Undersampling': RandomUnderSampler(random_state=42),
        'SMOTETomek': SMOTETomek(random_state=42)
    }
    
    for tech_name, sampler in techniques.items():
        print(f"\nğŸ”„ TÃ©cnica: {tech_name}")
        
        # Aplicar balanceo (si corresponde)
        if sampler:
            X_bal, y_bal = sampler.fit_resample(X_train, y_train)
        else:
            X_bal, y_bal = X_train, y_train
        
        # Entrenar los 3 modelos
        models = {
            'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
            'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)
        }
        
        for model_name, model in models.items():
            model.fit(X_bal, y_bal)
            result = evaluate(model, X_test, y_test, model_name, tech_name)
            all_results.append(result)
            print(f"   âœ… {model_name}: F1={result['F1-Score']:.4f}")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # CLASS WEIGHT (No modifica datos, solo pesos durante entrenamiento)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f"\nğŸ”„ TÃ©cnica: Class Weight")
    
    cw_models = {
        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced'),
        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),
    }
    
    for model_name, model in cw_models.items():
        model.fit(X_train, y_train)
        result = evaluate(model, X_test, y_test, model_name, 'Class Weight')
        all_results.append(result)
        print(f"   âœ… {model_name}: F1={result['F1-Score']:.4f}")
    
    return pd.DataFrame(all_results)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIÃ“N: OPTIMIZACIÃ“N CON GRIDSEARCHCV
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def optimize_models(X_train, X_test, y_train, y_test):
    """
    Optimiza hiperparÃ¡metros usando GridSearchCV con SMOTE.
    
    GridSearchCV realiza:
    1. Divide datos en K folds (5)
    2. Para cada combinaciÃ³n de parÃ¡metros:
       - Entrena en K-1 folds
       - Valida en 1 fold
       - Repite K veces
    3. Selecciona mejor combinaciÃ³n basada en F1-Score
    """
    print("\n" + "=" * 70)
    print("ğŸ”§ OPTIMIZACIÃ“N CON GRIDSEARCHCV")
    print("=" * 70)
    
    # Aplicar SMOTE primero
    smote = SMOTE(random_state=42)
    X_smote, y_smote = smote.fit_resample(X_train, y_train)
    
    results = []
    best_models = {}
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Random Forest - ParÃ¡metros a optimizar
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nğŸ“Š Optimizando Random Forest...")
    rf_grid = GridSearchCV(
        RandomForestClassifier(random_state=42),
        param_grid={
            'n_estimators': [50, 100, 200],      # NÃºmero de Ã¡rboles
            'max_depth': [5, 10, 15, None],       # Profundidad mÃ¡xima
            'min_samples_split': [2, 5, 10]       # Muestras mÃ­nimas para dividir
        },
        cv=5, scoring='f1', n_jobs=-1
    )
    rf_grid.fit(X_smote, y_smote)
    print(f"   Mejores params: {rf_grid.best_params_}")
    print(f"   Mejor F1 (CV): {rf_grid.best_score_:.4f}")
    best_models['Random Forest'] = rf_grid.best_estimator_
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Logistic Regression - ParÃ¡metros a optimizar
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nğŸ“Š Optimizando Logistic Regression...")
    lr_grid = GridSearchCV(
        LogisticRegression(random_state=42, max_iter=1000),
        param_grid={
            'C': [0.01, 0.1, 1, 10],              # RegularizaciÃ³n inversa
            'solver': ['lbfgs', 'saga']           # Algoritmo
        },
        cv=5, scoring='f1', n_jobs=-1
    )
    lr_grid.fit(X_smote, y_smote)
    print(f"   Mejores params: {lr_grid.best_params_}")
    print(f"   Mejor F1 (CV): {lr_grid.best_score_:.4f}")
    best_models['Logistic Regression'] = lr_grid.best_estimator_
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Gradient Boosting - ParÃ¡metros a optimizar
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nğŸ“Š Optimizando Gradient Boosting...")
    gb_grid = GridSearchCV(
        GradientBoostingClassifier(random_state=42),
        param_grid={
            'n_estimators': [50, 100],            # NÃºmero de Ã¡rboles
            'learning_rate': [0.05, 0.1, 0.2],    # Tasa de aprendizaje
            'max_depth': [3, 5, 7]                 # Profundidad
        },
        cv=5, scoring='f1', n_jobs=-1
    )
    gb_grid.fit(X_smote, y_smote)
    print(f"   Mejores params: {gb_grid.best_params_}")
    print(f"   Mejor F1 (CV): {gb_grid.best_score_:.4f}")
    best_models['Gradient Boosting'] = gb_grid.best_estimator_
    
    # Evaluar modelos optimizados en test set
    for name, model in best_models.items():
        result = evaluate(model, X_test, y_test, name, 'SMOTE + GridSearch')
        results.append(result)
        print(f"\nâœ… {name} Optimizado: F1={result['F1-Score']:.4f}")
    
    return pd.DataFrame(results), best_models


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIÃ“N: VISUALIZAR RESULTADOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def visualize_results(df_results, output_dir='outputs'):
    """Genera visualizaciones de resultados."""
    os.makedirs(output_dir, exist_ok=True)
    
    # Heatmap de F1-Score
    fig, ax = plt.subplots(figsize=(12, 6))
    
    pivot = df_results.pivot(index='Modelo', columns='TÃ©cnica', values='F1-Score')
    sns.heatmap(pivot, annot=True, fmt='.3f', cmap='RdYlGn', 
                vmin=0, vmax=1, ax=ax)
    ax.set_title('F1-Score por Modelo y TÃ©cnica de Balanceo', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig(f'{output_dir}/heatmap_f1score.png', dpi=150)
    plt.close()
    print(f"\nâœ… GrÃ¡fico guardado: {output_dir}/heatmap_f1score.png")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if __name__ == "__main__":
    print("\n" + "ğŸ”¬" * 35)
    print("   PREDICCIÃ“N DE ANEMIA CON MACHINE LEARNING")
    print("ğŸ”¬" * 35)
    
    # Crear directorio de outputs
    os.makedirs('outputs', exist_ok=True)
    
    # 1. Cargar datos
    df = load_and_explore('TACNA_Final_Corregido.csv')
    
    # 2. Preprocesar
    X_train, X_test, y_train, y_test, scaler, features = preprocess(df)
    
    # 3. Entrenar con todas las tÃ©cnicas de balanceo
    df_techniques = train_all_techniques(X_train, X_test, y_train, y_test)
    
    # 4. Optimizar con GridSearchCV
    df_optimized, best_models = optimize_models(X_train, X_test, y_train, y_test)
    
    # 5. Combinar resultados
    df_all = pd.concat([df_techniques, df_optimized], ignore_index=True)
    
    # 6. Visualizar
    visualize_results(df_all)
    
    # 7. Mostrar tabla final
    print("\n" + "=" * 70)
    print("ğŸ“Š TABLA COMPARATIVA FINAL")
    print("=" * 70)
    print(df_all.sort_values('F1-Score', ascending=False).to_string(index=False))
    
    # 8. Mejor modelo
    best = df_all.loc[df_all['F1-Score'].idxmax()]
    print("\n" + "ğŸ†" * 25)
    print(f"\nğŸ† MEJOR COMBINACIÃ“N: {best['Modelo']} + {best['TÃ©cnica']}")
    print(f"   F1-Score:  {best['F1-Score']:.4f}")
    print(f"   Recall:    {best['Recall']:.4f}")
    print(f"   Precision: {best['Precision']:.4f}")
    print(f"   AUC-ROC:   {best['AUC-ROC']:.4f}")
    
    # 9. Guardar resultados
    df_all.to_csv('outputs/resultados_completos.csv', index=False)
    print("\nâœ… Resultados guardados: outputs/resultados_completos.csv")
    
    print("\n" + "=" * 70)
    print("âœ… PROCESO COMPLETADO")
    print("=" * 70)
